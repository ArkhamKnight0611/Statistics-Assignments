{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The three primary measures of central tendency used in statistics are:\n",
        "\n",
        "Mean (Average): The mean is calculated by summing all the data values and dividing by the total number of data points. It is often denoted by the symbol \"μ\" (mu) for a population mean and \"x̄\" (x-bar) for a sample mean. The formula for the mean is:\n",
        "\n",
        "Population Mean (μ) = (ΣX) / N\n",
        "Sample Mean (x̄) = (Σx) / n\n",
        "\n",
        "Where:\n",
        "\n",
        "ΣX or Σx represents the sum of all data values.\n",
        "N represents the total number of data points in the population.\n",
        "n represents the total number of data points in the sample.\n",
        "The mean represents the central or average value in a dataset and is sensitive to outliers.\n",
        "\n",
        "Median: The median is the middle value when the data points are arranged in ascending or descending order. If there is an even number of data points, the median is the average of the two middle values. It is denoted as \"Mdn\" or \"Med.\"\n",
        "\n",
        "To find the median:\n",
        "\n",
        "Arrange the data in order.\n",
        "If the dataset has an odd number of values, the median is the middle value.\n",
        "If the dataset has an even number of values, the median is the average of the two middle values.\n",
        "The median represents the middle or central value in a dataset and is less sensitive to outliers compared to the mean.\n",
        "\n",
        "Mode: The mode is the value that appears most frequently in the dataset. A dataset can have one mode (unimodal), multiple modes (multimodal), or no mode if all values are equally frequent. The mode is denoted as \"Mo\" or \"Mode.\"\n",
        "\n",
        "The mode is particularly useful for categorical and discrete data, where you are interested in identifying the most common category or value."
      ],
      "metadata": {
        "id": "fwf7WC49Gp_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean, median, and mode are three different measures of central tendency used in statistics to describe the central or typical value of a dataset. They each have distinct characteristics and are used in different situations:\n",
        "\n",
        "Mean (Average):\n",
        "\n",
        "Definition: The mean is calculated by summing all the data values and dividing by the total number of data points. It is represented by symbols such as \"μ\" (population mean) and \"x̄\" (sample mean).\n",
        "Use: The mean represents the arithmetic average of the dataset and is commonly used to measure central tendency. It provides a balanced estimate of the central value by considering all data points equally.\n",
        "Sensitivity: The mean is sensitive to outliers or extreme values in the dataset. A single outlier can significantly affect the mean, pulling it in the direction of the outlier.\n",
        "Median:\n",
        "\n",
        "Definition: The median is the middle value when the data points are arranged in ascending or descending order. If there is an even number of data points, the median is the average of the two middle values.\n",
        "Use: The median represents the middle or central value in a dataset. It is robust to outliers and extreme values, making it suitable for datasets with skewed distributions or when outliers need to be avoided.\n",
        "Sensitivity: The median is less sensitive to outliers compared to the mean because it is based on the position of values rather than their actual magnitude.\n",
        "Mode:\n",
        "\n",
        "Definition: The mode is the value that appears most frequently in the dataset. A dataset can have one mode (unimodal), multiple modes (multimodal), or no mode if all values are equally frequent.\n",
        "Use: The mode is particularly useful for categorical and discrete data, where you want to identify the most common category or value. In continuous data, it can still be used to identify peaks or clusters in the distribution.\n",
        "Sensitivity: The mode is not affected by the magnitude of values, only their frequency. It is not sensitive to outliers."
      ],
      "metadata": {
        "id": "S-rh2DePHAWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wv1iaWzf-86m"
      },
      "outputs": [],
      "source": [
        "a=[178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "OPeGiuyuHKUz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZYNMujEHcYk",
        "outputId": "c935f691-4465-45d5-89d3-8e8015470a14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177.01875"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.median(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XopBhM43Hk2b",
        "outputId": "4841f437-53ce-435b-d236-50cdabcc9cc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177.0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats.mode(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd_bsk4FHmNU",
        "outputId": "37427134-9214-46dc-9c39-9f50f78f24ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModeResult(mode=177.0, count=3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b=[178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]"
      ],
      "metadata": {
        "id": "TMsMjsN5HoeR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtOvzUsXM7x0",
        "outputId": "218075e6-31ff-48b2-f4c0-6bd4191b74c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7885814036548633"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measures of dispersion, including range, variance, and standard deviation, are used to describe the spread or variability of a dataset. They provide valuable insights into how data points are distributed around the central tendency (mean, median, or mode) and help quantify the degree of scatter or spread within the data. Here's how each measure is used and an example:\n",
        "\n",
        "Range:\n",
        "\n",
        "Definition: The range is the simplest measure of dispersion and represents the difference between the maximum and minimum values in the dataset.\n",
        "Use: It provides a basic understanding of the spread of data by giving the range of values from the lowest to the highest.\n",
        "Example: Suppose you have a dataset of daily temperatures (in degrees Celsius) for a week: [15, 18, 14, 22, 19, 13, 23]. The range would be 23 (highest temperature) - 13 (lowest temperature) = 10°C. This indicates that the temperature varied by 10 degrees over the week.\n",
        "Variance:\n",
        "\n",
        "Definition: Variance measures the average of the squared differences between each data point and the mean. It quantifies how data points deviate from the mean.\n",
        "Use: It provides a more precise measure of the spread or dispersion of data than the range. A higher variance indicates greater variability.\n",
        "Example: Consider a dataset of test scores for a class: [85, 92, 78, 88, 95]. To calculate the variance, you would first find the mean (average), which is 87.6. Then, calculate the squared differences from the mean: [(85-87.6)^2, (92-87.6)^2, (78-87.6)^2, (88-87.6)^2, (95-87.6)^2]. The variance is the average of these squared differences.\n",
        "Standard Deviation:\n",
        "\n",
        "Definition: The standard deviation is the square root of the variance. It measures the average amount of deviation or dispersion of data points from the mean.\n",
        "Use: It is particularly useful because it has the same units as the original data, making it more interpretable. A smaller standard deviation suggests less variability, while a larger one indicates greater variability.\n",
        "Example: Using the same test scores dataset, if the variance is calculated to be 24.3, the standard deviation would be the square root of 24.3, which is approximately 4.93. This means that, on average, the test scores deviate from the mean by about 4.93 points."
      ],
      "metadata": {
        "id": "DwM0amiENLXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Venn diagram is a visual representation used to illustrate the relationships and commonalities between sets or groups of items or elements. It consists of overlapping circles, each representing a set, and the areas of overlap between the circles show the elements that belong to multiple sets. Venn diagrams are widely used in various fields, including mathematics, logic, statistics, and problem-solving, to visually display and analyze the relationships between different categories or groups of data.\n",
        "\n",
        "Key features of a Venn diagram include:\n",
        "\n",
        "Circles: Each circle in a Venn diagram represents a set or a category. The elements or members of the set are represented by points inside the circle.\n",
        "\n",
        "Overlapping Regions: When two or more circles overlap, the areas of overlap represent elements that belong to multiple sets. The size of the overlapping region indicates the number of common elements.\n",
        "\n",
        "Non-Overlapping Regions: The parts of each circle that do not overlap with any other circle represent elements that belong exclusively to that set.\n",
        "\n",
        "Venn diagrams are particularly useful for illustrating concepts related to set theory and for solving problems involving intersections, unions, differences, and complements of sets. They are also employed in data visualization to depict relationships and overlaps between different categories or groups of data. Venn diagrams can become more complex when representing relationships between more than three sets, resulting in more intricate diagrams with multiple overlapping regions."
      ],
      "metadata": {
        "id": "-OozGRrfNcfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = {2, 3, 4, 5, 6, 7}\n",
        "B = {0, 2, 6, 8, 10}\n",
        "intersection=A.intersection(B)\n",
        "union=A.union(B)\n",
        "intersection,union"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A7e0CREM_FT",
        "outputId": "1b5c14c6-4c6f-4f08-a977-f98cd5ef632f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({2, 6}, {0, 2, 3, 4, 5, 6, 7, 8, 10})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skewness is a statistical measure that describes the asymmetry or lack of symmetry in the distribution of data points within a dataset. It provides insight into the shape of the data distribution and helps us understand whether the data is concentrated more on one side of the mean compared to the other. In essence, skewness indicates the direction and degree to which a dataset deviates from a perfectly symmetric, bell-shaped (normal) distribution.\n",
        "\n",
        "There are three main types of skewness:\n",
        "\n",
        "Positive Skewness (Right Skewed): In a positively skewed distribution, the tail on the right side of the data is longer or fatter than the left side, and the majority of data points cluster to the left of the mean. This means that there are some unusually high values (outliers) that are pulling the mean in the positive direction.\n",
        "\n",
        "Positive Skewness\n",
        "\n",
        "In positively skewed data, the mean (average) is typically greater than the median.\n",
        "Common real-life examples of positively skewed data include income distribution, where a few individuals earn very high incomes, or exam scores, where a few students score significantly higher than the rest.\n",
        "Negative Skewness (Left Skewed): In a negatively skewed distribution, the tail on the left side of the data is longer or fatter than the right side, and most data points cluster to the right of the mean. This suggests that there are some unusually low values (outliers) that are pulling the mean in the negative direction.\n",
        "\n",
        "Negative Skewness\n",
        "\n",
        "In negatively skewed data, the mean is typically less than the median.\n",
        "An example of negatively skewed data could be the age at retirement, where most people retire at an older age, but a few retire early.\n",
        "Zero Skewness (Symmetric): In a symmetric distribution, data is evenly distributed on both sides of the mean, and the tails on both sides are approximately equal in length. This results in a balanced, bell-shaped curve resembling a normal distribution.\n",
        "\n",
        "Zero Skewness\n",
        "\n",
        "In symmetric data, the mean is equal to the median, and there is no skewness present.\n",
        "Examples of data with zero skewness include the heights of a population or the scores on a fair six-sided die."
      ],
      "metadata": {
        "id": "kQDCGcGNiMsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a right-skewed distribution (positively skewed), the median will typically be less than the mean. Here's why:\n",
        "\n",
        "Right Skewed Data: In a right-skewed distribution, the majority of data points are concentrated on the left side of the distribution, and there are a few unusually high values (outliers) on the right side that extend the tail in that direction. These outliers have a greater influence on the mean than on the median because the mean considers all data points.\n",
        "\n",
        "Median: The median is the middle value when the data is ordered from smallest to largest. Because the right-skewed data has most of its values on the left side, the median will be closer to the bulk of the data, which is on the left side. This results in the median being less than the mean.\n",
        "\n",
        "In summary, for right-skewed data:\n",
        "\n",
        "Mean > Median\n",
        "The mean is pulled to the right (toward the tail) by the presence of the high outliers, while the median remains closer to the center of the bulk of the data, which is on the left side of the distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QYJbwWuiilqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Covariance and correlation are both measures used in statistics to describe the relationship between two variables, particularly in the context of multivariate data analysis. However, they serve different purposes and have different properties:\n",
        "\n",
        "Covariance:\n",
        "\n",
        "Definition: Covariance is a measure of how two variables change together. It quantifies the degree to which two variables tend to increase or decrease at the same time. It is calculated as the average of the product of the deviations of each variable from their respective means.\n",
        "\n",
        "Formula: The formula for the covariance between two variables X and Y is given as:\n",
        "\n",
        "Cov(X,Y)=E[(X−EX)(Y−EY)]=E[XY]−(EX)(EY)\n",
        "\n",
        "Unit of Measurement: The unit of measurement of covariance is the product of the units of the two variables (e.g., square units if X and Y are lengths).\n",
        "\n",
        "Interpretation: A positive covariance indicates that as one variable increases, the other tends to increase as well, and vice versa for negative covariance. However, the magnitude of covariance is not standardized, so it can be challenging to compare covariances across different datasets.\n",
        "\n",
        "Range: Covariance can take any real value, which makes it difficult to interpret without context. Therefore, it's often used in conjunction with other statistics.\n",
        "\n",
        "Correlation:\n",
        "\n",
        "Definition: Correlation is a standardized measure that quantifies the strength and direction of the linear relationship between two variables. It provides a more interpretable measure of how two variables are related.\n",
        "\n",
        "Formula: The most commonly used correlation coefficient is the Pearson correlation coefficient (r), which is calculated as:\n",
        "\n",
        "r. r = ∑ i = 1 n ( x i − x ¯ ) ( y i − y ¯ ) ∑ i = 1 n ( x i − x ¯ ) 2 ∑ i = 1 n ( y i − y ¯ ) 2\n",
        "\n",
        "Range: The Pearson correlation coefficient ranges from -1 to 1, where:\n",
        "\n",
        "-1 indicates a perfect negative linear relationship.\n",
        "1 indicates a perfect positive linear relationship.\n",
        "0 indicates no linear relationship.\n",
        "Unit of Measurement: Correlation is a unitless measure, making it easier to compare relationships across different datasets.\n",
        "\n",
        "Usage in Statistical Analysis:\n",
        "\n",
        "Covariance: Covariance is used to identify whether two variables tend to move together or in opposite directions. It is a fundamental concept in statistics and is used in various statistical techniques, such as linear regression. However, its units make it less interpretable and less suitable for comparing relationships between different pairs of variables.\n",
        "\n",
        "Correlation: Correlation, particularly the Pearson correlation coefficient, is widely used in statistical analysis to measure and compare the strength and direction of linear relationships between variables. It is commonly used in fields such as finance, economics, social sciences, and natural sciences to assess the degree of association between variables. Correlation is also a key tool in data exploration and visualization.\n",
        "\n",
        "In summary, while covariance and correlation both describe the relationship between two variables, correlation provides a standardized and more interpretable measure of this relationship, making it a preferred choice in most cases for assessing the strength and direction of linear associations in data."
      ],
      "metadata": {
        "id": "g4lTHLDvi5nt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general formula for calculating the sample mean is given by x̄ = ( Σ xi ) / n. Here, x̄ represents the sample mean, xi refers all X sample values and n stands for the number of sample terms in the data set."
      ],
      "metadata": {
        "id": "sGtNJzbRjxMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset=[85,92,78,88,95]\n",
        "\n",
        "To find the sample mean (average) of these scores, you would:\n",
        "\n",
        "Add up all the individual scores:\n",
        "Σxi =85+92+78+88+95=438\n",
        "\n",
        "Divide the sum by the number of data points (in this case, 5, since there are 5 scores in the dataset):\n",
        "Σxi/5\n",
        "\n",
        "Sample Mean\n",
        "Σxi/5= 438/5=87.6\n",
        "So, the sample mean (average) score for these five students on the math test is 87.6."
      ],
      "metadata": {
        "id": "Y62JvWznj4S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a perfectly normal distribution, the three common measures of central tendency—mean, median, and mode—have a special relationship:\n",
        "\n",
        "Mean (Average): The mean of a normal distribution is equal to the median. This means that the center of the distribution, where the distribution is symmetrically divided into two equal halves, is located at the mean.\n",
        "\n",
        "Median (Middle Value): The median of a normal distribution is equal to the mean. As mentioned earlier, this is because the normal distribution is perfectly symmetric.\n",
        "\n",
        "Mode (Most Frequent Value): The mode of a normal distribution is also equal to the mean and the median. In a normal distribution, there is a single peak, and this peak corresponds to both the mean and the median."
      ],
      "metadata": {
        "id": "5tV2IYQgkgUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Range:\n",
        "\n",
        "Covariance: Covariance can take any real value, making it difficult to interpret without context. Its magnitude depends on the units of the variables.\n",
        "Correlation: Correlation coefficients range from -1 to 1, where -1 indicates a perfect negative linear relationship, 1 indicates a perfect positive linear relationship, and 0 indicates no linear relationship. Correlation is unitless, making it easier to compare relationships across different datasets.\n",
        "Interpretation:\n",
        "\n",
        "Covariance: A positive covariance indicates that as one variable increases, the other tends to increase as well (positive relationship), and vice versa for negative covariance (negative relationship). However, the magnitude of covariance is not standardized, so it can be challenging to compare covariances across different datasets.\n",
        "Correlation: Correlation provides a standardized measure of the strength and direction of the linear relationship. It is more interpretable, as values close to -1 or 1 indicate strong linear relationships, while values close to 0 suggest little to no linear relationship.\n",
        "Applicability:\n",
        "\n",
        "Covariance: Covariance is used to assess the degree of joint variability between two variables. It is a fundamental concept in statistics and is used in various statistical techniques, such as linear regression.\n",
        "Correlation: Correlation is widely used in statistical analysis and data science to measure and compare the strength and direction of linear associations between variables. It is particularly valuable when comparing relationships across different datasets because of its standardized scale.\n",
        "In summary, while both covariance and correlation describe the relationship between two variables, correlation provides a more standardized and interpretable measure of this relationship, making it the preferred choice in most cases for assessing the strength and direction of linear associations in data."
      ],
      "metadata": {
        "id": "MnhykERzkv1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers can have a significant impact on measures of central tendency (mean, median, mode) and measures of dispersion (range, variance, standard deviation) in a dataset. The extent of their impact depends on the nature and number of outliers. Here's how outliers affect these measures:\n",
        "\n",
        "Measures of Central Tendency:\n",
        "\n",
        "Mean: Outliers can strongly influence the mean because it takes into account the value of each data point. If you have a high outlier (a very large value) or a low outlier (a very small value), the mean can be pulled in the direction of the outlier. For instance, a single extremely high income in a salary dataset can significantly increase the mean salary.\n",
        "\n",
        "Example: Consider the following dataset of exam scores: [85, 92, 78, 88, 95, 150]. The mean score without the outlier is 89.67, but with the outlier, it becomes 105.33.\n",
        "\n",
        "Median: The median is less affected by outliers compared to the mean. It only considers the middle value(s) in the ordered dataset, so one or a few outliers won't have as much influence. In the example above, the median score remains 88 with or without the outlier.\n",
        "\n",
        "Mode: The mode is less affected by outliers as well because it represents the most frequently occurring value(s) in the dataset. Outliers, being rare, typically do not impact the mode.\n",
        "\n",
        "Measures of Dispersion:\n",
        "\n",
        "Range: Outliers can significantly impact the range because the range is the difference between the maximum and minimum values in the dataset. A single outlier can widen the range substantially.\n",
        "\n",
        "Example: In a dataset of ages [25, 28, 30, 35, 90], the range without the outlier is 10, but with the outlier, it becomes 65.\n",
        "\n",
        "Variance and Standard Deviation: Outliers can inflate both the variance and standard deviation because these measures take into account how individual data points deviate from the mean. Outliers, being far from the mean, contribute to higher variability.\n",
        "\n",
        "Example: In a dataset of test scores [85, 92, 78, 88, 95, 150], the variance and standard deviation are much higher when the outlier is included.\n",
        "\n",
        "In summary, outliers can distort measures of central tendency and dispersion, particularly the mean, range, variance, and standard deviation. It's important to identify and assess outliers in a dataset, as their presence can impact the interpretation and analysis of the data. Depending on the context and goals of the analysis, you may choose to handle outliers through techniques like data transformation, trimming, or using robust statistics that are less sensitive to extreme values.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CmDuIdKAk8Ag"
      }
    }
  ]
}